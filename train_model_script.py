import os
import ember
import multiprocessing
import numpy as np
import joblib
import lightgbm as lgb
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
# ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ SMOTE-Tomek ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á: pip install imbalanced-learn
from imblearn.combine import SMOTETomek 

if __name__ == '__main__':
    multiprocessing.freeze_support()
    
    data_dir = "D:/project/ember2018"
    model_dir = "D:/project/models"
    if not os.path.exists(model_dir):
        os.makedirs(model_dir)

    # --- Step 1: Feature Vectorization ---
    print("üöÄ 1/3 ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ Vectorization...")
    ember.create_vectorized_features(data_dir, feature_version=2)
    ember.create_metadata(data_dir)

    # --- Step 2: Model Training (Ensemble Learning Phase) ---
    print("üß† 2/3 ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• (Training Phase)...")
    X_train, y_train, X_test, y_test = ember.read_vectorized_features(data_dir, feature_version=2)
    
    # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (Unlabeled) ‡∏≠‡∏≠‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô
    train_rows = (y_train != -1)
    X_train, y_train = X_train[train_rows], y_train[train_rows]

    # ‡∏ó‡∏≥ Data Balancing ‡∏î‡πâ‡∏ß‡∏¢ SMOTE-Tomek ‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô‡∏†‡∏≤‡∏û
    print("‚öñÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ SMOTE-Tomek...")
    smt = SMOTETomek(random_state=42)
    X_resampled, y_resampled = smt.fit_resample(X_train, y_train)

    # --- ‡∏ù‡∏∂‡∏Å‡∏ù‡∏ô 3 ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏¢‡πà‡∏≠‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Ensemble Voting ---
    
    # 1. ‡πÄ‡∏ó‡∏£‡∏ô Random Forest (‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà)
    print("üå≤ ‡πÄ‡∏ó‡∏£‡∏ô Random Forest...")
    rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)
    rf.fit(X_resampled, y_resampled)
    joblib.dump(rf, os.path.join(model_dir, "random_forest.pkl"))

    # 2. ‡πÄ‡∏ó‡∏£‡∏ô Extra-Trees (‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏°‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞)
    print("üå≥ ‡πÄ‡∏ó‡∏£‡∏ô Extra-Trees...")
    et = ExtraTreesClassifier(n_estimators=100, n_jobs=-1, random_state=42)
    et.fit(X_resampled, y_resampled)
    joblib.dump(et, os.path.join(model_dir, "extra_trees.pkl"))

    # 3. ‡πÄ‡∏ó‡∏£‡∏ô LightGBM (‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î)
    print("üí° ‡πÄ‡∏ó‡∏£‡∏ô LightGBM...")
    lgbm_params = {"objective": "binary", "metric": "auc", "verbosity": -1}
    dtrain = lgb.Dataset(X_resampled, label=y_resampled)
    lgbm_model = lgb.train(lgbm_params, dtrain, num_boost_round=100)
    lgbm_model.save_model(os.path.join(model_dir, "lgbm_model.txt"))

    print(f"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ñ‡∏π‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà: {model_dir}")